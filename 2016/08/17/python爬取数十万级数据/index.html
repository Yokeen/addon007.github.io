<!DOCTYPE html>
<html lang=en>
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
    <meta name="description" content="前言 需要使用的模块beautifulsoup,然后结合mongodb来存放数据  使用beautifulsoup来爬取网页信息原理 我们可以通过审核元素来copy目标的路径信息，比较常用的有css selector和xpath(xpath被誉为神器，也比较容易理解，但是先学习beautifulsoup),但是beautifulsoup只认识css selector.所以我们通过复制目标的css">
<meta name="keywords" content="python">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬取十万级数据">
<meta property="og:url" content="http://lessismore.cool/2016/08/17/python爬取数十万级数据/index.html">
<meta property="og:site_name" content="Yokeen&#39;s blog">
<meta property="og:description" content="前言 需要使用的模块beautifulsoup,然后结合mongodb来存放数据  使用beautifulsoup来爬取网页信息原理 我们可以通过审核元素来copy目标的路径信息，比较常用的有css selector和xpath(xpath被誉为神器，也比较容易理解，但是先学习beautifulsoup),但是beautifulsoup只认识css selector.所以我们通过复制目标的css">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2018-11-29T13:33:11.294Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python爬取十万级数据">
<meta name="twitter:description" content="前言 需要使用的模块beautifulsoup,然后结合mongodb来存放数据  使用beautifulsoup来爬取网页信息原理 我们可以通过审核元素来copy目标的路径信息，比较常用的有css selector和xpath(xpath被誉为神器，也比较容易理解，但是先学习beautifulsoup),但是beautifulsoup只认识css selector.所以我们通过复制目标的css">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>python爬取十万级数据</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" "top"="" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/tags/">Tags</a></li>
         
          <li><a href="/friend/">Friend</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </span>
    <br>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post " href="/2016/08/17/blog-start/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Back to top " href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post " href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://lessismore.cool/2016/08/17/python爬取数十万级数据/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&text=python爬取十万级数据"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&is_video=false&description=python爬取十万级数据"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=python爬取十万级数据&body=Check out this article: http://lessismore.cool/2016/08/17/python爬取数十万级数据/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&name=python爬取十万级数据&description=&lt;h1 id=&#34;前言&#34;&gt;&lt;a href=&#34;#前言&#34; class=&#34;headerlink&#34; title=&#34;前言&#34;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;需要使用的模块beautifulsoup,然后结合mongodb来存放数据&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;使用beautifulsoup来爬取网页信息原理&#34;&gt;&lt;a href=&#34;#使用beautifulsoup来爬取网页信息原理&#34; class=&#34;headerlink&#34; title=&#34;使用beautifulsoup来爬取网页信息原理&#34;&gt;&lt;/a&gt;使用beautifulsoup来爬取网页信息原理&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;我们可以通过审核元素来copy目标的路径信息，比较常用的有css selector和xpath(xpath被誉为神器，也比较容易理解，但是先学习beautifulsoup),但是beautifulsoup只认识css selector.所以我们通过复制目标的css selector来做到爬取它的目标&lt;br&gt;"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://news.ycombinator.com/submitlink?u=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&t=python爬取十万级数据"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#使用beautifulsoup来爬取网页信息原理"><span class="toc-number">1.1.</span> <span class="toc-text">使用beautifulsoup来爬取网页信息原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#关于xpath和css-selector"><span class="toc-number">1.2.</span> <span class="toc-text">关于xpath和css selector</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#beautifulsoup使用方法"><span class="toc-number">1.3.</span> <span class="toc-text">beautifulsoup使用方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mongodb使用方法"><span class="toc-number">1.4.</span> <span class="toc-text">mongodb使用方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实战-开始爬取58同城数据"><span class="toc-number">2.</span> <span class="toc-text">实战-开始爬取58同城数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#first-py"><span class="toc-number">2.1.</span> <span class="toc-text">first.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#second-py"><span class="toc-number">2.2.</span> <span class="toc-text">second.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#third-py"><span class="toc-number">2.3.</span> <span class="toc-text">third.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#fourth-py"><span class="toc-number">2.4.</span> <span class="toc-text">fourth,py</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        python爬取十万级数据
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
        <span itemprop="name">Yokeen</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2016-08-17T05:59:24.000Z" itemprop="datePublished">2016-08-17</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/python/">python</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p>需要使用的模块beautifulsoup,然后结合mongodb来存放数据</p>
</blockquote>
<h2 id="使用beautifulsoup来爬取网页信息原理"><a href="#使用beautifulsoup来爬取网页信息原理" class="headerlink" title="使用beautifulsoup来爬取网页信息原理"></a>使用beautifulsoup来爬取网页信息原理</h2><blockquote>
<p>我们可以通过审核元素来copy目标的路径信息，比较常用的有css selector和xpath(xpath被誉为神器，也比较容易理解，但是先学习beautifulsoup),但是beautifulsoup只认识css selector.所以我们通过复制目标的css selector来做到爬取它的目标<br><a id="more"></a></p>
</blockquote>
<h2 id="关于xpath和css-selector"><a href="#关于xpath和css-selector" class="headerlink" title="关于xpath和css selector"></a>关于xpath和css selector</h2><blockquote>
<p>xpath : 谁，在哪，第几个<br>css selector : 谁，在哪，第几个，长什么样子</p>
</blockquote>
<h2 id="beautifulsoup使用方法"><a href="#beautifulsoup使用方法" class="headerlink" title="beautifulsoup使用方法"></a>beautifulsoup使用方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">* 导入所需要的库</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">* 指定Url</span><br><span class="line">url = <span class="string">""</span></span><br><span class="line">* 使用request来获取网页内容</span><br><span class="line">data = requests.get(url)</span><br><span class="line">* 使用beautifulsoup来解析网页</span><br><span class="line">soup = BeautifulSoup(data.text,<span class="string">'lxml'</span>)</span><br><span class="line">* 使用浏览器的审核元素，copy想要爬去元素的css selector</span><br><span class="line">titles = soup.select(<span class="string">'xxxxxx'</span>)</span><br><span class="line">tags = soup.select(<span class="string">''</span>)</span><br><span class="line">imgs = soup.select(<span class="string">'img[width="30"]'</span>)</span><br><span class="line">****</span><br><span class="line">注意：</span><br><span class="line">---文章的标签通常是多对一结构，要获得一个信息的所有标签，就要在标签的父级目录停下来</span><br><span class="line">---可以在select中添加目标的特殊信息，例如soup.select(<span class="string">'img[width="30"]'</span>)筛选出img标签中宽为<span class="number">10</span>的图片。</span><br><span class="line">****</span><br><span class="line">* 筛选信息，将他们装在一个字典中</span><br><span class="line"><span class="keyword">for</span> title,tag,img <span class="keyword">in</span> zip(titles,tags,imgs):</span><br><span class="line">	data = &#123;</span><br><span class="line">		<span class="string">'title'</span>:title.get_text(),  <span class="comment">#get_text方法是获取标签的正文</span></span><br><span class="line">		<span class="string">'tag'</span>:list(tag.stripped_strings)  如果用get_text只会获取其中的一个，stripped_strings算是get_text的升级版本，获取一个父级标签下所有子标签的正文</span><br><span class="line">		<span class="string">'img'</span>:img.get(<span class="string">'src'</span>)  get是获取标签的属性值，对于图片，我们通常爬取的是他的链接</span><br><span class="line">&#125;</span><br><span class="line">	print(data)</span><br></pre></td></tr></table></figure>
<p>如果要对他进行优化，比如我想筛选出评分大于3的文章<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">info = []</span><br><span class="line">info.append(data)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> info:</span><br><span class="line">	<span class="keyword">if</span> i[<span class="string">'cate'</span>]&gt;<span class="number">3</span>:</span><br><span class="line">		print(i[<span class="string">'title'</span>])</span><br><span class="line">		....</span><br></pre></td></tr></table></figure></p>
<hr>
<p>小技巧，比如爬取图片地址，有些地址是在js文件中，所以爬取很麻烦，我们可以通过chrome浏览器中的模拟手机功能来利用相同的方法来抓取，因为手机端不会加载过多的js文件，这样一来爬取图片链接也简单了许多。</p>
<p>注意：使用request记得在里边添加headers，让服务器知道你是手机端而不是电脑。</p>
<h2 id="mongodb使用方法"><a href="#mongodb使用方法" class="headerlink" title="mongodb使用方法"></a>mongodb使用方法</h2><p>对于下载和使用mongodb可以参考<a href="http://www.runoob.com/mongodb/mongodb-tutorial.html" target="_blank" rel="noopener">MongoDB 教程</a><br>还有pycharm中mongo插件的使用，以及下载安装与mongodb做连接的pymongo库…</p>
<blockquote>
<p>对于代码中mongodb的创建，我们可以把他和execl来联系起来。我们先要给一个表名称，而这个表的主体内容还可以分为sheet1，sheet2….<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">* 导入可以与mongodb连接的库文件，当然前提你要安装Mongodb</span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line">* 激活mongodb，因为我们是部署在本地中，所以创建在本地</span><br><span class="line">client = pymongo.MongoClient(<span class="string">'localhost'</span>,<span class="number">27017</span>)</span><br><span class="line">* 给execl一个标题</span><br><span class="line">execl0 = client(<span class="string">'execl0'</span>) 左边的是Python对象，右边的是mongodb中数据库名称，建议一致</span><br><span class="line">* 给execl一个sheet</span><br><span class="line">sheet1 = execl0[<span class="string">'sheet1'</span>] 在execl0中创建一个sheet</span><br><span class="line">* 此处从beautifulsoup那里连接开始</span><br><span class="line">	sheet1.insert_one(data) 这个是在表execl0中的sheet1中插入数据</span><br><span class="line">* 使用find来找出数据,find后边可以添加条件，条件要为字典格式。使用以下指令来进行筛选，$lt/$lte/$gt/$gte/$ne依次等价于 &lt;、&lt;=、&gt;、&gt;=、！=。</span><br><span class="line">*格式   sheet1.find(&#123;<span class="string">'评分'</span>:$lt3&#125;)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> sheet1.find():   </span><br><span class="line">	<span class="keyword">print</span> item</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h1 id="实战-开始爬取58同城数据"><a href="#实战-开始爬取58同城数据" class="headerlink" title="实战-开始爬取58同城数据"></a>实战-开始爬取58同城数据</h1><h2 id="first-py"><a href="#first-py" class="headerlink" title="first.py"></a>first.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># client = pymongo.MongoClient('localhost',27017)</span></span><br><span class="line"><span class="comment"># walden = client['walden']</span></span><br><span class="line"><span class="comment"># sheet = walden['sheet']</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://jq.58.com/sale.shtml'</span></span><br><span class="line">url_host = <span class="string">'http://jq.58.com/'</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_info</span><span class="params">(url)</span>:</span></span><br><span class="line">    web_data = requests.get(url)</span><br><span class="line">    soup = BeautifulSoup(web_data.text,<span class="string">'lxml'</span>)</span><br><span class="line">    links = soup.select(<span class="string">'ul.ym-submnu &gt; li &gt; b &gt; a'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> links:</span><br><span class="line">        page = url_host + i.get(<span class="string">'href'</span>)</span><br><span class="line">        print(page)</span><br><span class="line">chew_link = <span class="string">'''</span></span><br><span class="line"><span class="string">http://jq.58.com//shouji/</span></span><br><span class="line"><span class="string">http://jq.58.com//shoujihao/</span></span><br><span class="line"><span class="string">http://jq.58.com//tongxunyw/</span></span><br><span class="line"><span class="string">http://jq.58.com//danche/</span></span><br><span class="line"><span class="string">http://jq.58.com//fzixingche/</span></span><br><span class="line"><span class="string">http://jq.58.com//diandongche/</span></span><br><span class="line"><span class="string">http://jq.58.com//sanlunche/</span></span><br><span class="line"><span class="string">http://jq.58.com//peijianzhuangbei/</span></span><br><span class="line"><span class="string">http://jq.58.com//diannao/</span></span><br><span class="line"><span class="string">http://jq.58.com//bijiben/</span></span><br><span class="line"><span class="string">http://jq.58.com//pbdn/</span></span><br><span class="line"><span class="string">http://jq.58.com//diannaopeijian/</span></span><br><span class="line"><span class="string">http://jq.58.com//zhoubianshebei/</span></span><br><span class="line"><span class="string">http://jq.58.com//shuma/</span></span><br><span class="line"><span class="string">http://jq.58.com//shumaxiangji/</span></span><br><span class="line"><span class="string">http://jq.58.com//mpsanmpsi/</span></span><br><span class="line"><span class="string">http://jq.58.com//youxiji/</span></span><br><span class="line"><span class="string">http://jq.58.com//jiadian/</span></span><br><span class="line"><span class="string">http://jq.58.com//dianshiji/</span></span><br><span class="line"><span class="string">http://jq.58.com//ershoukongtiao/</span></span><br><span class="line"><span class="string">http://jq.58.com//xiyiji/</span></span><br><span class="line"><span class="string">http://jq.58.com//bingxiang/</span></span><br><span class="line"><span class="string">http://jq.58.com//binggui/</span></span><br><span class="line"><span class="string">http://jq.58.com//chuang/</span></span><br><span class="line"><span class="string">http://jq.58.com//ershoujiaju/</span></span><br><span class="line"><span class="string">http://jq.58.com//bangongshebei/</span></span><br><span class="line"><span class="string">http://jq.58.com//diannaohaocai/</span></span><br><span class="line"><span class="string">http://jq.58.com//bangongjiaju/</span></span><br><span class="line"><span class="string">http://jq.58.com//ershoushebei/</span></span><br><span class="line"><span class="string">http://jq.58.com//yingyou/</span></span><br><span class="line"><span class="string">http://jq.58.com//yingeryongpin/</span></span><br><span class="line"><span class="string">http://jq.58.com//muyingweiyang/</span></span><br><span class="line"><span class="string">http://jq.58.com//muyingtongchuang/</span></span><br><span class="line"><span class="string">http://jq.58.com//yunfuyongpin/</span></span><br><span class="line"><span class="string">http://jq.58.com//fushi/</span></span><br><span class="line"><span class="string">http://jq.58.com//nanzhuang/</span></span><br><span class="line"><span class="string">http://jq.58.com//fsxiemao/</span></span><br><span class="line"><span class="string">http://jq.58.com//xiangbao/</span></span><br><span class="line"><span class="string">http://jq.58.com//meirong/</span></span><br><span class="line"><span class="string">http://jq.58.com//yishu/</span></span><br><span class="line"><span class="string">http://jq.58.com//shufahuihua/</span></span><br><span class="line"><span class="string">http://jq.58.com//zhubaoshipin/</span></span><br><span class="line"><span class="string">http://jq.58.com//yuqi/</span></span><br><span class="line"><span class="string">http://jq.58.com//tushu/</span></span><br><span class="line"><span class="string">http://jq.58.com//tushubook/</span></span><br><span class="line"><span class="string">http://jq.58.com//wenti/</span></span><br><span class="line"><span class="string">http://jq.58.com//yundongfushi/</span></span><br><span class="line"><span class="string">http://jq.58.com//jianshenqixie/</span></span><br><span class="line"><span class="string">http://jq.58.com//huju/</span></span><br><span class="line"><span class="string">http://jq.58.com//qiulei/</span></span><br><span class="line"><span class="string">http://jq.58.com//yueqi/</span></span><br><span class="line"><span class="string">http://jq.58.com//chengren/</span></span><br><span class="line"><span class="string">http://jq.58.com//nvyongpin/</span></span><br><span class="line"><span class="string">http://jq.58.com//qinglvqingqu/</span></span><br><span class="line"><span class="string">http://jq.58.com//qingquneiyi/</span></span><br><span class="line"><span class="string">http://jq.58.com//chengren/</span></span><br><span class="line"><span class="string">http://jq.58.com//xiaoyuan/</span></span><br><span class="line"><span class="string">http://jq.58.com//ershouqiugou/</span></span><br><span class="line"><span class="string">http://jq.58.com//tiaozao/</span></span><br><span class="line"><span class="string">http://jq.58.com//tiaozao/</span></span><br><span class="line"><span class="string">http://jq.58.com//tiaozao/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="second-py"><a href="#second-py" class="headerlink" title="second.py"></a>second.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">client = pymongo.MongoClient(<span class="string">'localhost'</span>,<span class="number">27017</span>)</span><br><span class="line">walden = client[<span class="string">'walden'</span>]</span><br><span class="line">sheet = walden[<span class="string">'sheet'</span>]</span><br><span class="line">info = walden[<span class="string">'info'</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_link</span><span class="params">(url,page,who_sell=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="comment">#http://jq.58.com/shouji/</span></span><br><span class="line">    chew_list = <span class="string">'&#123;&#125;&#123;&#125;/pn&#123;&#125;'</span>.format(url,str(who_sell),str(page))</span><br><span class="line">    web_data = requests.get(chew_list)</span><br><span class="line">    soup = BeautifulSoup(web_data.text,<span class="string">'lxml'</span>)</span><br><span class="line">    src = soup.select(<span class="string">' div.infocon &gt; table &gt; tbody &gt; tr.zzinfo &gt; td.t &gt; a'</span>)</span><br><span class="line">    <span class="keyword">for</span> links <span class="keyword">in</span> src:</span><br><span class="line">        a = links.get(<span class="string">'href'</span>).split(<span class="string">'?'</span>)[<span class="number">0</span>]</span><br><span class="line">        sheet.insert_one(&#123;<span class="string">'link'</span>:a&#125;)</span><br><span class="line">        print(a)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_info</span><span class="params">(url)</span>:</span></span><br><span class="line">    web_data = requests.get(url)</span><br><span class="line">    soup = BeautifulSoup(web_data.text,<span class="string">'lxml'</span>)</span><br><span class="line">    title = soup.title.text</span><br><span class="line">    price = soup.select(<span class="string">'div.info_lubotu.clearfix &gt; div.info_massege.left &gt; div.price_li &gt; span'</span>)[<span class="number">0</span>].text</span><br><span class="line">    area = soup.select(<span class="string">'div.info_lubotu.clearfix &gt; div.info_massege.left &gt; div.palce_li &gt; span'</span>)[<span class="number">0</span>].text</span><br><span class="line">    info.insert_one(&#123;</span><br><span class="line">        <span class="string">'title'</span>:title,</span><br><span class="line">        <span class="string">'price'</span>:price,</span><br><span class="line">        <span class="string">'area'</span>:area</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="third-py"><a href="#third-py" class="headerlink" title="third.py"></a>third.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">from</span> first <span class="keyword">import</span> chew_link</span><br><span class="line"><span class="keyword">from</span> second <span class="keyword">import</span> get_link</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_link</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">101</span>):</span><br><span class="line">        get_link(url,num)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pool = Pool()</span><br><span class="line">    pool.map(total_link,chew_link.split())</span><br></pre></td></tr></table></figure>
<h2 id="fourth-py"><a href="#fourth-py" class="headerlink" title="fourth,py"></a>fourth,py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> second <span class="keyword">import</span> sheet</span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    print(sheet.find().count())</span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>以上就是python+mongodb+beautifulsoup+多进程 来爬取十万级数据的方法，但是比较懒，还有好多优化的地方以变得更加方便以及更少的代码，但是没有进行优化…这是一大不足</p>
</blockquote>
<blockquote>
<p>fourth.py实现了一个数据库计数的功能。third.py结合first.py,second.py的方法，在结合多进程来来实现。</p>
</blockquote>
<blockquote>
<p>second.py是爬取通过first传递过来的所需要的信息。运行时运行fourth和third就可以了。</p>
</blockquote>
<p>QQ:709516041  如有不懂的可以来问我，也欢迎有大神前来指点我的不足</p>
<p>同时也在此感谢俊富给我的资料。</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/tags/">Tags</a></li>
         
          <li><a href="/friend/">Friend</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#前言"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#使用beautifulsoup来爬取网页信息原理"><span class="toc-number">1.1.</span> <span class="toc-text">使用beautifulsoup来爬取网页信息原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#关于xpath和css-selector"><span class="toc-number">1.2.</span> <span class="toc-text">关于xpath和css selector</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#beautifulsoup使用方法"><span class="toc-number">1.3.</span> <span class="toc-text">beautifulsoup使用方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mongodb使用方法"><span class="toc-number">1.4.</span> <span class="toc-text">mongodb使用方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实战-开始爬取58同城数据"><span class="toc-number">2.</span> <span class="toc-text">实战-开始爬取58同城数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#first-py"><span class="toc-number">2.1.</span> <span class="toc-text">first.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#second-py"><span class="toc-number">2.2.</span> <span class="toc-text">second.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#third-py"><span class="toc-number">2.3.</span> <span class="toc-text">third.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#fourth-py"><span class="toc-number">2.4.</span> <span class="toc-text">fourth,py</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://lessismore.cool/2016/08/17/python爬取数十万级数据/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&text=python爬取十万级数据"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&is_video=false&description=python爬取十万级数据"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=python爬取十万级数据&body=Check out this article: http://lessismore.cool/2016/08/17/python爬取数十万级数据/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&title=python爬取十万级数据"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&name=python爬取十万级数据&description=&lt;h1 id=&#34;前言&#34;&gt;&lt;a href=&#34;#前言&#34; class=&#34;headerlink&#34; title=&#34;前言&#34;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;需要使用的模块beautifulsoup,然后结合mongodb来存放数据&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;使用beautifulsoup来爬取网页信息原理&#34;&gt;&lt;a href=&#34;#使用beautifulsoup来爬取网页信息原理&#34; class=&#34;headerlink&#34; title=&#34;使用beautifulsoup来爬取网页信息原理&#34;&gt;&lt;/a&gt;使用beautifulsoup来爬取网页信息原理&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;我们可以通过审核元素来copy目标的路径信息，比较常用的有css selector和xpath(xpath被誉为神器，也比较容易理解，但是先学习beautifulsoup),但是beautifulsoup只认识css selector.所以我们通过复制目标的css selector来做到爬取它的目标&lt;br&gt;"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://news.ycombinator.com/submitlink?u=http://lessismore.cool/2016/08/17/python爬取数十万级数据/&t=python爬取十万级数据"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2021
    Yokeen
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/tags/">Tags</a></li>
         
          <li><a href="/friend/">Friend</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'">


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->


</body>
</html>
